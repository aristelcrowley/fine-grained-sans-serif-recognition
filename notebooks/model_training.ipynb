{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20bc6ce9",
   "metadata": {},
   "source": [
    "# Model Training — Fine-Grained Sans-Serif Font Recognition\n",
    "\n",
    "This notebook trains a deep CNN to classify **20 sans-serif font families** from synthetic text images.\n",
    "\n",
    "**Architecture:** **EfficientNet-B2** (pretrained on ImageNet) with a custom classification head — chosen for fine-grained recognition because:\n",
    "- **Compound scaling** captures both coarse structure (letter shape) and fine detail (stroke width, terminal geometry) simultaneously\n",
    "- Superior parameter efficiency vs ResNet/VGG at similar accuracy\n",
    "- Proven on fine-grained benchmarks (CUB-200, Stanford Cars, etc.)\n",
    "\n",
    "**Training strategy:**\n",
    "1. **Frozen backbone warm-up** (5 epochs) — train only the classifier head on top of frozen ImageNet features\n",
    "2. **Full fine-tuning** (25 epochs) — unfreeze all layers with differential learning rates (backbone 10× lower) and cosine annealing\n",
    "3. **Mixed-precision (AMP)** — faster training on Kaggle T4/P100 GPUs\n",
    "\n",
    "**Outputs:** Best model checkpoint (`.pth`) + full training metadata for local inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fa03d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "# ── Reproducibility ──\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"PyTorch {torch.__version__}  •  Device: {DEVICE}\")\n",
    "if DEVICE.type == \"cuda\":\n",
    "    print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  Memory: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15712b5",
   "metadata": {},
   "source": [
    "## 1 · Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070c6f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_KAGGLE = os.path.exists(\"/kaggle\")\n",
    "\n",
    "if IS_KAGGLE:\n",
    "    DATA_DIR   = \"/kaggle/input/domain-randomized-sans-serif-fonts\"\n",
    "    SAVE_DIR   = \"/kaggle/working\"\n",
    "else:\n",
    "    DATA_DIR   = \"../data/processed\"\n",
    "    SAVE_DIR   = \"../models\"\n",
    "\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, \"train\")\n",
    "TEST_DIR  = os.path.join(DATA_DIR, \"test\")\n",
    "\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# Hyperparameters\n",
    "\n",
    "NUM_CLASSES      = 20\n",
    "IMG_SIZE         = 224\n",
    "BATCH_SIZE       = 64\n",
    "NUM_WORKERS      = 2\n",
    "\n",
    "# Phase 1: Frozen backbone warm-up\n",
    "WARMUP_EPOCHS    = 5\n",
    "WARMUP_LR        = 1e-3\n",
    "\n",
    "# Phase 2: Full fine-tuning\n",
    "FINETUNE_EPOCHS  = 25\n",
    "BACKBONE_LR      = 1e-4         # Lower LR for pretrained layers\n",
    "HEAD_LR          = 1e-3         # Higher LR for new classifier head\n",
    "WEIGHT_DECAY     = 1e-4\n",
    "\n",
    "# Early stopping\n",
    "PATIENCE         = 7            # Stop if val loss doesn't improve for 7 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4a5517",
   "metadata": {},
   "source": [
    "## 2 · Data Pipeline\n",
    "\n",
    "Images are variable-sized text rectangles, resized to **224×224** and normalized to ImageNet statistics.\n",
    "\n",
    "Since the dataset was already **heavily augmented offline** (7 TRDG profiles + post-processing with JPEG compression, brightness/contrast jitter, salt-and-pepper noise, and dark-mode inversion), the online training transforms are kept **minimal and non-overlapping**:\n",
    "\n",
    "- **Random horizontal flip** (p=0.05) — very rare, simulates mirrored screenshots\n",
    "- **Random erasing** (p=0.1) — simulates partial occlusion (NOT covered offline)\n",
    "- **Random grayscale** (p=0.05) — desaturated captures\n",
    "\n",
    "**Test transforms** apply only deterministic resize + normalization (no augmentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215c3e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms  \n",
    "# ImageNet normalization stats (required for pretrained EfficientNet)\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.05),    # rare flip — mirrored screenshots\n",
    "    transforms.RandomGrayscale(p=0.05),          # desaturated captures\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "    transforms.RandomErasing(p=0.1, scale=(0.02, 0.08)),  # partial occlusion (not in offline aug)\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "])\n",
    "\n",
    "# Datasets & Loaders  \n",
    "\n",
    "train_dataset = datasets.ImageFolder(TRAIN_DIR, transform=train_transforms)\n",
    "test_dataset  = datasets.ImageFolder(TEST_DIR,  transform=test_transforms)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "    num_workers=NUM_WORKERS, pin_memory=True, drop_last=True,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=NUM_WORKERS, pin_memory=True,\n",
    ")\n",
    "\n",
    "# Class names (sorted alphabetically by ImageFolder)\n",
    "CLASS_NAMES = train_dataset.classes\n",
    "idx_to_class = {i: c for i, c in enumerate(CLASS_NAMES)}\n",
    "\n",
    "print(f\"Train : {len(train_dataset):,} images\")\n",
    "print(f\"Test  : {len(test_dataset):,} images\")\n",
    "print(f\"Classes ({len(CLASS_NAMES)}): {CLASS_NAMES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a555444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick sanity check: visualize a batch\n",
    "\n",
    "def denormalize(tensor, mean=IMAGENET_MEAN, std=IMAGENET_STD):\n",
    "    \"\"\"Undo ImageNet normalization for display.\"\"\"\n",
    "    t = tensor.clone()\n",
    "    for ch, m, s in zip(t, mean, std):\n",
    "        ch.mul_(s).add_(m)\n",
    "    return t.clamp_(0, 1)\n",
    "\n",
    "imgs, labels = next(iter(train_loader))\n",
    "\n",
    "fig, axes = plt.subplots(2, 8, figsize=(20, 5))\n",
    "fig.suptitle(\"Training Batch Sample (with augmentation)\", fontsize=14)\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img = denormalize(imgs[i]).permute(1, 2, 0).numpy()\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(CLASS_NAMES[labels[i]], fontsize=9)\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43712aee",
   "metadata": {},
   "source": [
    "## 3 · Model Architecture\n",
    "\n",
    "**EfficientNet-B2** backbone with a custom classification head:\n",
    "\n",
    "```\n",
    "EfficientNet-B2 (frozen/unfrozen backbone)\n",
    "    └─ AdaptiveAvgPool → 1408-d feature vector\n",
    "        └─ Dropout(0.3)\n",
    "            └─ Linear(1408 → 512) + ReLU + BatchNorm\n",
    "                └─ Dropout(0.2)\n",
    "                    └─ Linear(512 → 20)\n",
    "```\n",
    "\n",
    "The two-layer head with BatchNorm helps the model learn a more discriminative font embedding compared to a single linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400824c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_classes: int = NUM_CLASSES, dropout: float = 0.3) -> nn.Module:\n",
    "    \"\"\"\n",
    "    EfficientNet-B2 with a custom 2-layer classification head.\n",
    "    Returns the model with backbone frozen (ready for Phase 1).\n",
    "    \"\"\"\n",
    "    # Load pretrained EfficientNet-B2\n",
    "    weights = models.EfficientNet_B2_Weights.IMAGENET1K_V1\n",
    "    model = models.efficientnet_b2(weights=weights)\n",
    "    \n",
    "    # Freeze backbone\n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # ─Replace classifier head\n",
    "    # EfficientNet-B2 has 1408 features before the classifier\n",
    "    in_features = model.classifier[1].in_features  # 1408\n",
    "    \n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(p=dropout),\n",
    "        nn.Linear(in_features, 512),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.BatchNorm1d(512),\n",
    "        nn.Dropout(p=0.2),\n",
    "        nn.Linear(512, num_classes),\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_model().to(DEVICE)\n",
    "\n",
    "# Count parameters\n",
    "total_params   = sum(p.numel() for p in model.parameters())\n",
    "frozen_params  = sum(p.numel() for p in model.parameters() if not p.requires_grad)\n",
    "trainable      = total_params - frozen_params\n",
    "\n",
    "print(f\"Model: EfficientNet-B2\")\n",
    "print(f\"  Total params     : {total_params:>10,}\")\n",
    "print(f\"  Frozen (backbone): {frozen_params:>10,}\")\n",
    "print(f\"  Trainable (head) : {trainable:>10,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886be913",
   "metadata": {},
   "source": [
    "## 4 · Training Engine\n",
    "\n",
    "Core training/validation loop with:\n",
    "- **Mixed-precision (AMP)** for ~2× speedup on T4\n",
    "- **Gradient clipping** to stabilize fine-tuning\n",
    "- **Early stopping** on validation loss to prevent overfitting\n",
    "- Per-epoch metrics tracking for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7b338e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)  # slight smoothing helps fine-grained tasks\n",
    "scaler   = GradScaler()                               # for mixed-precision\n",
    "\n",
    "# ── History tracking ──\n",
    "history = {\n",
    "    \"train_loss\": [], \"train_acc\": [],\n",
    "    \"val_loss\": [],   \"val_acc\": [],\n",
    "    \"lr\": [],\n",
    "}\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, epoch_num):\n",
    "    \"\"\"Train for one epoch with AMP. Returns (avg_loss, accuracy).\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(loader, desc=f\"  Train Ep {epoch_num}\", leave=False)\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, preds = outputs.max(1)\n",
    "        correct += preds.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        pbar.set_postfix(loss=f\"{loss.item():.4f}\", acc=f\"{correct/total:.4f}\")\n",
    "    \n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, epoch_num):\n",
    "    \"\"\"Evaluate on validation/test set. Returns (avg_loss, accuracy).\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(loader, desc=f\"  Val   Ep {epoch_num}\", leave=False)\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        \n",
    "        with autocast():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, preds = outputs.max(1)\n",
    "        correct += preds.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "\n",
    "def run_training(model, optimizer, scheduler, num_epochs, phase_name=\"Training\"):\n",
    "    \"\"\"\n",
    "    Run training loop with early stopping.\n",
    "    Returns the best model state dict and best val accuracy.\n",
    "    \"\"\"\n",
    "    best_val_acc  = 0.0\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    epochs_no_improve = 0\n",
    "    best_val_loss = float(\"inf\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\" {phase_name} — {num_epochs} epochs\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        t0 = time.time()\n",
    "        \n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, epoch)\n",
    "        val_loss, val_acc     = evaluate(model, test_loader, epoch)\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        \n",
    "        # Track current LR\n",
    "        current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "        history[\"lr\"].append(current_lr)\n",
    "        \n",
    "        elapsed = time.time() - t0\n",
    "        print(f\"  Epoch {epoch:>2d}/{num_epochs}  \"\n",
    "              f\"train_loss={train_loss:.4f}  train_acc={train_acc:.4f}  \"\n",
    "              f\"val_loss={val_loss:.4f}  val_acc={val_acc:.4f}  \"\n",
    "              f\"lr={current_lr:.2e}  ({elapsed:.0f}s)\")\n",
    "        \n",
    "        # Early stopping logic\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_val_acc  = val_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            epochs_no_improve = 0\n",
    "            print(f\"    ★ New best model (val_acc={val_acc:.4f})\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= PATIENCE:\n",
    "                print(f\"    ✗ Early stopping triggered (no improvement for {PATIENCE} epochs)\")\n",
    "                break\n",
    "    \n",
    "    # Restore best weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    print(f\"\\n  ✓ {phase_name} complete — best val_acc: {best_val_acc:.4f}\")\n",
    "    return best_val_acc\n",
    "\n",
    "print(\"✓ Training engine ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10206fb",
   "metadata": {},
   "source": [
    "## 5 · Phase 1 — Frozen Backbone Warm-Up\n",
    "\n",
    "Train **only the classifier head** (backbone frozen) for 5 epochs. This lets the new layers converge to reasonable weights before we unfreeze the backbone and risk corrupting pretrained features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f8f9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 1: Only classifier head is trainable (backbone frozen from build_model)\n",
    "optimizer_warmup = optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=WARMUP_LR,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    ")\n",
    "scheduler_warmup = optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer_warmup, T_max=WARMUP_EPOCHS, eta_min=1e-5\n",
    ")\n",
    "\n",
    "phase1_acc = run_training(\n",
    "    model, optimizer_warmup, scheduler_warmup,\n",
    "    num_epochs=WARMUP_EPOCHS,\n",
    "    phase_name=\"Phase 1 · Frozen Backbone Warm-Up\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f0ebdf",
   "metadata": {},
   "source": [
    "## 6 · Phase 2 — Full Fine-Tuning\n",
    "\n",
    "Unfreeze the **entire backbone** and train with **differential learning rates**:\n",
    "- Backbone layers: `1e-4` (gentle updates to preserve pretrained features)\n",
    "- Classifier head: `1e-3` (aggressive updates for task-specific learning)\n",
    "\n",
    "Cosine annealing smoothly decays both rates to near-zero over 25 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00df1f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze backbone\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Differential learning rates\n",
    "optimizer_finetune = optim.AdamW([\n",
    "    {\"params\": model.features.parameters(), \"lr\": BACKBONE_LR},   # backbone: lower LR\n",
    "    {\"params\": model.classifier.parameters(), \"lr\": HEAD_LR},     # head: higher LR\n",
    "], weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "scheduler_finetune = optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer_finetune, T_max=FINETUNE_EPOCHS, eta_min=1e-6\n",
    ")\n",
    "\n",
    "# Report new param counts\n",
    "trainable_now = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Unfroze backbone — trainable params: {trainable_now:,}\")\n",
    "\n",
    "phase2_acc = run_training(\n",
    "    model, optimizer_finetune, scheduler_finetune,\n",
    "    num_epochs=FINETUNE_EPOCHS,\n",
    "    phase_name=\"Phase 2 · Full Fine-Tuning\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64a375b",
   "metadata": {},
   "source": [
    "## 7 · Training Curves\n",
    "\n",
    "Plot loss, accuracy, and learning rate across both training phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b1449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "epochs_range = range(1, len(history[\"train_loss\"]) + 1)\n",
    "\n",
    "# Phase boundary line\n",
    "phase_boundary = WARMUP_EPOCHS + 0.5\n",
    "\n",
    "# Loss\n",
    "ax = axes[0]\n",
    "ax.plot(epochs_range, history[\"train_loss\"], \"b-o\", markersize=3, label=\"Train Loss\")\n",
    "ax.plot(epochs_range, history[\"val_loss\"],   \"r-o\", markersize=3, label=\"Val Loss\")\n",
    "ax.axvline(phase_boundary, color=\"grey\", ls=\"--\", alpha=0.5, label=\"Phase 1→2\")\n",
    "ax.set_xlabel(\"Epoch\"); ax.set_ylabel(\"Loss\"); ax.set_title(\"Loss\")\n",
    "ax.legend(); ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "ax = axes[1]\n",
    "ax.plot(epochs_range, history[\"train_acc\"], \"b-o\", markersize=3, label=\"Train Acc\")\n",
    "ax.plot(epochs_range, history[\"val_acc\"],   \"r-o\", markersize=3, label=\"Val Acc\")\n",
    "ax.axvline(phase_boundary, color=\"grey\", ls=\"--\", alpha=0.5, label=\"Phase 1→2\")\n",
    "ax.set_xlabel(\"Epoch\"); ax.set_ylabel(\"Accuracy\"); ax.set_title(\"Accuracy\")\n",
    "ax.legend(); ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Learning Rate\n",
    "ax = axes[2]\n",
    "ax.plot(epochs_range, history[\"lr\"], \"g-o\", markersize=3)\n",
    "ax.axvline(phase_boundary, color=\"grey\", ls=\"--\", alpha=0.5, label=\"Phase 1→2\")\n",
    "ax.set_xlabel(\"Epoch\"); ax.set_ylabel(\"LR\"); ax.set_title(\"Learning Rate Schedule\")\n",
    "ax.set_yscale(\"log\"); ax.legend(); ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(\"Training History (Phase 1: Warm-Up  |  Phase 2: Fine-Tune)\", fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b9a096",
   "metadata": {},
   "source": [
    "## 8 · Evaluation — Confusion Matrix & Classification Report\n",
    "\n",
    "Full evaluation on the **held-out test set** (20% of data, never seen during training).\n",
    "- **Confusion matrix** reveals which font pairs the model struggles to distinguish\n",
    "- **Per-class precision / recall / F1** for the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e37948a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_all_predictions(model, loader):\n",
    "    \"\"\"Collect all predictions and ground truth labels.\"\"\"\n",
    "    model.eval()\n",
    "    all_preds  = []\n",
    "    all_labels = []\n",
    "    all_probs  = []\n",
    "    \n",
    "    for images, labels in tqdm(loader, desc=\"Evaluating\", leave=False):\n",
    "        images = images.to(DEVICE)\n",
    "        with autocast():\n",
    "            outputs = model(images)\n",
    "        \n",
    "        probs = torch.softmax(outputs, dim=1).cpu()\n",
    "        preds = outputs.argmax(dim=1).cpu()\n",
    "        \n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(labels)\n",
    "        all_probs.append(probs)\n",
    "    \n",
    "    return (\n",
    "        torch.cat(all_preds).numpy(),\n",
    "        torch.cat(all_labels).numpy(),\n",
    "        torch.cat(all_probs).numpy(),\n",
    "    )\n",
    "\n",
    "y_pred, y_true, y_probs = get_all_predictions(model, test_loader)\n",
    "\n",
    "# Classification Report\n",
    "print(\"=\" * 70)\n",
    "print(\" CLASSIFICATION REPORT\")\n",
    "print(\"=\" * 70)\n",
    "print(classification_report(y_true, y_pred, target_names=CLASS_NAMES, digits=4))\n",
    "\n",
    "# Overall accuracy\n",
    "overall_acc = (y_pred == y_true).mean()\n",
    "print(f\"\\n  Overall Test Accuracy: {overall_acc:.4f} ({overall_acc*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c890df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix Heatmap\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm_pct = cm.astype(\"float\") / cm.sum(axis=1, keepdims=True) * 100  # normalize to %\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(24, 10))\n",
    "\n",
    "# Raw counts\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES, ax=axes[0])\n",
    "axes[0].set_title(\"Confusion Matrix (Counts)\", fontsize=14)\n",
    "axes[0].set_xlabel(\"Predicted\"); axes[0].set_ylabel(\"True\")\n",
    "axes[0].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "# Percentage (per-row normalized)\n",
    "sns.heatmap(cm_pct, annot=True, fmt=\".1f\", cmap=\"Oranges\",\n",
    "            xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES, ax=axes[1])\n",
    "axes[1].set_title(\"Confusion Matrix (% per True Class)\", fontsize=14)\n",
    "axes[1].set_xlabel(\"Predicted\"); axes[1].set_ylabel(\"True\")\n",
    "axes[1].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Top confused pairs (for paper discussion)\n",
    "print(\"\\nTop 10 Most Confused Font Pairs:\")\n",
    "print(\"-\" * 50)\n",
    "np.fill_diagonal(cm, 0)  # ignore correct predictions\n",
    "for _ in range(10):\n",
    "    i, j = np.unravel_index(cm.argmax(), cm.shape)\n",
    "    if cm[i, j] == 0:\n",
    "        break\n",
    "    print(f\"  {CLASS_NAMES[i]:>14s} → {CLASS_NAMES[j]:<14s}  ({cm[i,j]} misclassifications)\")\n",
    "    cm[i, j] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34092c96",
   "metadata": {},
   "source": [
    "## 9 · Per-Class Accuracy Bar Chart\n",
    "\n",
    "Visual breakdown of which fonts are easiest/hardest to recognize — useful for the paper's analysis section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131fd1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompute clean confusion matrix for per-class accuracy\n",
    "cm_clean = confusion_matrix(y_true, y_pred)\n",
    "per_class_acc = cm_clean.diagonal() / cm_clean.sum(axis=1)\n",
    "\n",
    "# Sort by accuracy\n",
    "sorted_idx = np.argsort(per_class_acc)\n",
    "sorted_names = [CLASS_NAMES[i] for i in sorted_idx]\n",
    "sorted_acc   = per_class_acc[sorted_idx]\n",
    "\n",
    "# Color: green for high accuracy, red for low\n",
    "colors = plt.cm.RdYlGn(sorted_acc)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "bars = ax.barh(sorted_names, sorted_acc * 100, color=colors, edgecolor=\"grey\", linewidth=0.5)\n",
    "\n",
    "# Add value labels\n",
    "for bar, acc in zip(bars, sorted_acc):\n",
    "    ax.text(bar.get_width() + 0.3, bar.get_y() + bar.get_height()/2,\n",
    "            f\"{acc*100:.1f}%\", va=\"center\", fontsize=10)\n",
    "\n",
    "ax.set_xlabel(\"Accuracy (%)\", fontsize=12)\n",
    "ax.set_title(\"Per-Class Test Accuracy\", fontsize=14)\n",
    "ax.set_xlim(0, 105)\n",
    "ax.axvline(overall_acc * 100, color=\"blue\", ls=\"--\", alpha=0.5, label=f\"Mean: {overall_acc*100:.1f}%\")\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(axis=\"x\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aeb12df",
   "metadata": {},
   "source": [
    "## 10 · Sample Predictions\n",
    "\n",
    "Visual spot-check: show 20 random test images with true vs predicted labels. Green = correct, Red = wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf1c615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random sample predictions\n",
    "rng = np.random.RandomState(42)\n",
    "sample_indices = rng.choice(len(test_dataset), size=20, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(4, 5, figsize=(20, 12))\n",
    "fig.suptitle(\"Sample Test Predictions  (Green=Correct, Red=Wrong)\", fontsize=15, y=1.01)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    idx = sample_indices[i]\n",
    "    img_tensor, true_label = test_dataset[idx]\n",
    "    \n",
    "    # Display image (denormalized)\n",
    "    img_display = denormalize(img_tensor).permute(1, 2, 0).numpy()\n",
    "    ax.imshow(img_display)\n",
    "    \n",
    "    # Prediction\n",
    "    pred_label = y_pred[idx]\n",
    "    true_name = CLASS_NAMES[true_label]\n",
    "    pred_name = CLASS_NAMES[pred_label]\n",
    "    confidence = y_probs[idx][pred_label] * 100\n",
    "    \n",
    "    correct = pred_label == true_label\n",
    "    color = \"green\" if correct else \"red\"\n",
    "    \n",
    "    ax.set_title(\n",
    "        f\"True: {true_name}\\nPred: {pred_name} ({confidence:.0f}%)\",\n",
    "        fontsize=9, color=color, fontweight=\"bold\"\n",
    "    )\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFinal Test Accuracy: {overall_acc*100:.2f}%\")\n",
    "print(\"Training complete! Download best_model.pth and model_metadata.json from Kaggle Output.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22d36d4",
   "metadata": {},
   "source": [
    "## 11 · Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62449e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Checkpoint\n",
    "\n",
    "checkpoint_path = os.path.join(SAVE_DIR, \"best_model.pth\")\n",
    "metadata_path   = os.path.join(SAVE_DIR, \"model_metadata.json\")\n",
    "\n",
    "# Checkpoint: state dict + everything needed to reconstruct\n",
    "checkpoint = {\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"architecture\":     \"efficientnet_b2\",\n",
    "    \"num_classes\":      NUM_CLASSES,\n",
    "    \"img_size\":         IMG_SIZE,\n",
    "    \"class_names\":      CLASS_NAMES,\n",
    "    \"idx_to_class\":     idx_to_class,\n",
    "    \"imagenet_mean\":    IMAGENET_MEAN,\n",
    "    \"imagenet_std\":     IMAGENET_STD,\n",
    "    \"best_val_acc\":     phase2_acc,\n",
    "    \"total_epochs\":     len(history[\"train_loss\"]),\n",
    "    \"history\":          history,\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, checkpoint_path)\n",
    "ckpt_size = os.path.getsize(checkpoint_path) / (1024 * 1024)\n",
    "print(f\"✓ Checkpoint saved: {checkpoint_path} ({ckpt_size:.1f} MB)\")\n",
    "\n",
    "# Human-readable metadata JSON (for the inference notebook)\n",
    "metadata = {\n",
    "    \"architecture\":  \"efficientnet_b2\",\n",
    "    \"num_classes\":   NUM_CLASSES,\n",
    "    \"img_size\":      IMG_SIZE,\n",
    "    \"class_names\":   CLASS_NAMES,\n",
    "    \"imagenet_mean\": IMAGENET_MEAN,\n",
    "    \"imagenet_std\":  IMAGENET_STD,\n",
    "    \"best_val_acc\":  round(phase2_acc, 4),\n",
    "    \"training_info\": {\n",
    "        \"warmup_epochs\":   WARMUP_EPOCHS,\n",
    "        \"finetune_epochs\": FINETUNE_EPOCHS,\n",
    "        \"total_epochs\":    len(history[\"train_loss\"]),\n",
    "        \"batch_size\":      BATCH_SIZE,\n",
    "        \"backbone_lr\":     BACKBONE_LR,\n",
    "        \"head_lr\":         HEAD_LR,\n",
    "        \"label_smoothing\": 0.1,\n",
    "    },\n",
    "}\n",
    "\n",
    "with open(metadata_path, \"w\") as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print(f\"✓ Metadata saved: {metadata_path}\")\n",
    "\n",
    "print(f\"\\n  Download these two files from Kaggle Output:\")\n",
    "print(f\"    1. {os.path.basename(checkpoint_path)}\")\n",
    "print(f\"    2. {os.path.basename(metadata_path)}\")\n",
    "print(f\"  Place them in your local  models/  directory for inference.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
